{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-25 | Unit Project 4: Notebook with Executive Summary | Answer Key\n",
    "\n",
    "In this project, you will summarize and present your analysis from Unit Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 1.  Introduction\n",
    "> Write a problem statement for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Problem statement for this project is to summarize the analysis that was done throughout unit projects 1 through 3. I think the focus on this project is predominantly on the UCLA data set that we were working with throughout all of these projects. However unit-project one did have a different problem statement related to converting customers to subscriptions based on features and factors provided. \n",
    "\n",
    "The problem statement from unit-project 1 regarding the UCLA dataset was to determine if there was a correlation between passing test scores and overall passing grades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 2.  Dataset\n",
    "> Write up a description of your data and any cleaning that was completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The initial data exploration revealed that the data set included a mix between categorical and continuous variables. The features included are a binary of whether or not the student was admitted to UCLA for graduate school, their respective gre scores, gpa, and the prestige of the undergraduate school they attended. The latter, the prestige had an integer rank of 1 through 4. \n",
    "\n",
    "The initial data exploration also included looking at the distribution of variables and testing for colinearity by looking at correlation tables. \n",
    "\n",
    "The plan for cleaning the data included, looking for outliers and dropping the NaN values for all the features as necessary. \n",
    "\n",
    "Following the exploratory data analysis the hypothesis became: is there an association between graduate school admission rates and the prestige of the undergraduate schools. My hypothessi was null. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> ## Question 3.  Demo\n",
    "> Provide a table that explains the data by admission status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Mean (std) or count by admission status for each feature:\n",
    "\n",
    "| Not Admitted | Admitted\n",
    "---|---|---\n",
    "GPA | mean (std) | mean (std)\n",
    "GRE | mean (std) | mean (std)\n",
    "Prestige 1 | count | count\n",
    "Prestige 2 | count | count\n",
    "Prestige 3 | count | count\n",
    "Prestige 4 | count | count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable | Not Admitted | Admitted\n",
    "---|---|---\n",
    "GPA | 3.3 (.37) | 3.5 (.37)\n",
    "GRE | 573.6 (116.1) | 618.6 (109.3)\n",
    "Prestige 1 | 28 | 33\n",
    "Prestige 2 | 95 | 53\n",
    "Prestige 3 | 93 | 28\n",
    "Prestige 4 | 55 | 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 4. Methods\n",
    "> Write up the methods used in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For my analysis, at least for the part that I got was to create a crosstab of prestige versus admitted. This got me the counts that I needed for admitted versus not admitted. \n",
    "\n",
    "The rest of the analysis included creating dummy variables for prestige and using that one hot encoding to calculate odds ratio for admittance versus not. \n",
    "\n",
    "Then we fit a logistic regression model to predict admission to UCLA using gre, gpa, and the prestige of the undergraduate schools. For this analysis the highest prestige of undergraduate schools was used as a reference point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how I calculated the initial calculations for the conditional mean. \n",
    "\n",
    "df_admit = df[df.admit == 1]\n",
    "df_admit.mean()\n",
    "df_admit.std()\n",
    "df_noadmit = df[df.admit == 0]\n",
    "df_noadmit.mean()\n",
    "df_noadmit.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 5. Results\n",
    "> Write up your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds ratio indicated that individuals that attended a top ranked undergraduate school have three times the chance of getting into graduate school than those that didn't. I am not sure if this is right though because I think that an odds ratio of 1 indicates there there is no difference in admittance between those that attended a top ranked school and those that didn't. Similarly, another odds ratio calculation indicated that: I think this means that individuals that did not attend the least prestigiously ranked schools have two times the chance of getting into grad school than those that did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 6. Visuals\n",
    "> Provide a table or visualization of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The only table I could provide is the one from unit project 3 ln[150] where we initially trained the model. This gives all the standard responses of a statsmodel logit regression model. I am not entirely sure how to get that here without a lot of effort so instead I will just refer to it here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 7.  Discussion\n",
    "> Write up your discussion and future steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I am not going to work on this project anymore so there are no future steps for me with regard to this. However, I suppose that you could try to refine the model more if you chose to. I am not entirely sure how, but this is what I am working on for my final. I think the way this regression was set up was such that each feature variable feature was factured into the predictive model but I think that these could be weighted and some might not be features at all. This is where I want to do PCA or know how to do PCA to figure out which variables are more important as playing into the output. I would also probably do some more inferential stats around this more exploration that made it more clear which variables were impacting the outcome more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
